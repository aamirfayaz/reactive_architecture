--> In this course we will look at a balance between consistency and availability in distributed systems.
--> A system is said to be scalable, if it can meet increases in demand while remaining responsive.
--> A system is said to be consistent, if all memebers of the system have same view or state.
--> A system is said to be available, if it remains responsive despite any failures.

========Scalability==============
-->Perfomance and Scalability are related, but different concepts. Performance optimizes response time. Scalability optimizes ability to handle load.
--> Improving Performance speeds up response time (i.e the latency), total number of requests (e.g load) may not change.
--> Improving Scalability increases ability to handle load. Performance of each request may not change.
--> Requests/second is a way to measure Performance and Scalability. Performance has a limit, can't go to zero response time, but theoretically no limit on Scalability.
--> Reactive Microservices tend to focus on Scalability.

==========Consistency=================
--> Distributed systems are systems that are separated by space.
--> Physics puts an upper limit on information speed (The Speed of Light)
--> When two systems are separated by space, there is always time required to reach consensus. 
--> In the time it takes to transfer the information, the state of the original sender may have changed.
--> The problem is, this means that the receiver of that information is always dealing with stale data.
--> This applies whether we are talking about computer science, people, or even just the physical world.
--> Reality is therefore Eventually Consistent.
--Eventual Consistency ----
--> E.C guarantees that, in the absence of new updates, all accesses to a specific piece of data will eventually return the most recent value.
--> E.C: In order to reach a state of consistency, you have to stop all updates, at-least for some period of time in order to reach that level of consistency.
--Strong Consistency ----
--> An update to a piece of data need agreement from all nodes before it become visible.
--Strong Consistency in an Eventually Consistent world--
--> Physics prevents Strong Consistency, so mechanisms are introduced to simulate it.
--> Locks allows systems to simulate Strong Consistency.
--> Distributed systems are isolated to non-distributed locks.
--> Locks introduce overhead in the form of a contention (hinders our ability to be elastic, resilient etc), so cost associated to it.
 --> Collaborating on Code Cloud Edits with acquiring locks is a good example of Strong Consistency.
 --> Modern Version Control systems are Eventually Consistent, they attain consistency through merge.
 
 ===The Effects of Contention============
 --> Any two things that contend for a single resource are in competiton.This competiton has one winner, others are forced to wait for winner to complete.
     As the number of things competing increases, the time to free up the resource increases. As load increases, we will eventually exceed acceptable time limits.	
 --> Amdahl's law defines the maximum improvement gained by parallel processing.
 --> Improvements from parallelization are limited to the code that can be parallized.
 --> Contention limits parallelization and therefore reduces the improvement.
 --> Amdahl's law shows the effect of contention on a distributed system.
 --> A key part of Amdahl's Law is to recognize that Contention limits parallelization.
 --> OR even if we try to parallelize, if we have contention in our systems, then we will get diminishing results.
 
 =====Coherency Delay==================
 --> In distributed system, synchronization of the state of multiple nodes is done using crosstalk or gossip.
 --> Each node in the system will send messages to every other node informing them of any state changes till they reach a state of Coherence where they all agree on the state of the system.
 --> The time it takes for this synchronization to complete is called Coherency Delay.
 --> Increasing the number of nodes increases the Coherency Delay.
 --> Gunther's Universal Scalability Law:
     - Gunther's Universal Scalability Law builds on Amdahl's law.
     - In addition to contention, it accounts for Coherency Delay.
     - Coherency Delay results in negative returns.
     - As the system scales up, the cost to coordinate between nodes exceeds any benefits.	
--> Gunther's Universal Scalability Law demonstrates that increasing concurrency can cause negative returns due to contention and coherency delay.     
     ==Goal is to try to get as close as possible to our Linear Scalability line as possible. (--Fantasy--)
     
====Laws of Scalability=============
--> Amdhal's law, Gunther's law of scalability, show was that linear scalability is almost impossible to achieve.
--> The myth of man-month book: adding manpower to a late software project makes it later. This idea is known as Brooks's law,
--> Both Amdhal and Gunther law's demonstrate linear scalability is almost always unachievable.
--> Linear Scalability requires total isolation. Basically Stateless.
--> Reactive systems understand the limitations imposed by these laws.
--> They try to exploit the limitations, rather than avoiding them.

====Scalability in Reactive Systems============
-->Reactive Systems reduce Contention by:
   - Isolating Locks, Eliminating transactions, Avoiding Blocking Operations.
--> They mitigate Coherence Dealys by:
   - Embracing Eventual Consistency.
   - Building in Autonomy.
--> This allows for higher Scalability.
--> The goal is to reduce or eliminate the things that prevent Scalability.   

====CAP Theorm============
--> Distributed systems must account for the CAP theorm [Eric Brewer].
--> The CAP theorm states that a distributed sysem can not provides more than two of the following:
    -> Consistency, Availability, Partition Tolerance.
--> Partition tolerance means the system continues to operate despite an arbitrary number of messages being 
    dropped (or delayed) by the network.	    
--> The theorm talks about trade-offs between Consistency and Availability that we have to make if our system
    ever suffers partitions.
--> Formalizes the trade-off between consistency and availability in the presence of partitions.
--> A read/write "Concern" on NOSql db.In the cluster of database nodes, each node will communicate the current state of the system with other nodes through a form of replication called gossip.

--> Sometimes we need to be consistent (strong), but also allow our systems to scale. Consistency creates Contention. Contention means Scalability will have diminishing,
    or even negative returns. How can we balance the need for Strong Consistency with the need for Scalability? By Isolating Contention...
    --> To improve scalability, we seek to eliminate contention, and reduce crosstalk. when they can't be eliminated, we try to isolate them instead.
    --> Locks with a broad scope (e.g Table Locks) create a lot of contention.
    --> Locks with a smaller scope (e.g Row/Record Locks) create less contention.
    --> Reactive system can use a technique called Sharding to limit the scope of the contention, and reduce crosstalk.
    --> Sharding is applied within the application (rather than the database.)


====Sharding for Consistency============
-->Sharding is a technique that provides strong consistency.Has techniques to minimize communication between the application and the database.
--> Sharding partitions Entities (or Actors) in the domain according to their Id.
--> Each Entity exists in only one shard.
--> Each Shard exists in only one location.
--> Because each entity lives in only one location, we eliminate the distributed system problem. The Entity acts as a consistency boundary.
--> simulating, entity A == Reservation A on Shard A-B on 1 node.
--> A Coordinator ensures traffic for a particular entity is routed to the correct location.
--> The Id of the Entity is used to calculate the appropriate Shard.
--> All traffic for a particular entity Id goes through the same entity.
--> Aggregate Roots are a good candidate for Sharding.
--> Balancing Shards:
    - Id or Shard Key selection is important to ensure shards are balanced.
    - A good shard key provides an even, randomized distribution.
    - Common Sharding strategies include using UUIDs or hash codes to ensure a randomized distribution.
    - Poor key selection results in hotspots.
    -You should aim for approximately 10x as many shards as you have nodes.	
===Effects of Sharding================
--> Understanding where its appropriate to use, means what are its benefits/drawbacks.
--> Contention in a Sharded System:
  --> Sharding doesn't eliminate Contention, it isolates it.
  --> within a single entity, there is contention. e.g xerox machine only one we have , with long line of message, here xerox is actor.
  --> The Router/Coordinator represents a source of contention as well.
  --> A sharded system minimizes contention by:
     - Limiting the amount of work the Router/Coordinator performs.
     - Isolating contention to individual entities.
--> Sharding, Consistency, and Scalability:
  --> Scalability is achieved by distributing the shards over more machines.
  --> Strong Consistency is achieved by isolating operations to a specific entity.
  --> Careful choice of shard keys is important to maintain good scalability.
  
--> Sharding and the CAP Theorm
  --> Sharding is primarily Consistency (CP) solution, therefore it sacrifices Availability.
  --> If a shard goes down then there is a period of time where it is unavailable.
  --> The shard will migrate to another node eventually.
  
--> Benefit: Caching With Shards
  --> Caching is problematic in a distributed system.
  --> How do you maintain cache consistency with multiple writers.
  --> Sharding allows each entity to maintain cache consistency.
  --> The Cache is unique to that entity.
  --> So all our ops to db are writes only.
  --> Most applications are read heavy.Almost never going to db, reads straight from Cache, so big benefit.


=====Availability and Scalability=================
--> We established Sharding as a technique we can use when we want Consistency.
--> It gives us a good balance betweeen Consistency and Scalability.
--> The CAP Theorm forces us to choose between Consistency or Availability.
--> What if we would prefer to have Availability rather than Consistency?
--> CRDTS [Conflict Free Repliated Datatypes]provides a highly available solution based on asynchronous replication.

====CRDTS for availability===========
--> Applied at the application level [in our code], dbs do also, but here we aren't talking about that.
--> CRDTs are highly available and Eventually Consistent e.g G-Set
    - Data is stored on multiple replicas for availability.
    - Updates are applied on one replica and then copied asynchronously.
    - Updates are merged to determine final statel.
    - CRDTs are a solution for Availability (AP) CAP Theorm.
    - Two Types: CvRDTs(Convergent Repliated Data Types), CmRDTs(Commutative Replicated Data Types)
    - CvRDTs copy states between replicas, requires a merge operation that understands how to combine two states.
    - Merge operation must be Commutative(can be applied in any order), Associative(Can be grouped in any order),
      Idempotent (Duplicated operations don't change the result)

    - CmRDTs copy operations between replicas.
--> In addition to G-Sets, tehre are several other existing CRDT types including Registers, Counters, Sets, Maps etc.
--> CRDT data types can be nested to create comples structures.
--> You can create new data types if you can define an appropriate merge function.
--> Akka Distributed Data implements CRDTs, Currently only supports CvRDTs, supports various data types including:
	Counters, Sets, maps, Registers.
	
====Effects of CRDTs==========
--> CRDTs in Distributed Data are stored in memory, Require that the entire sturcture fit into available memory.
--> They can optionally be copied to disk as well: This speed up recovery if a replica fails, During normal operation
	, all data is still in memory.
--> Best used for small data sets, with infrequent updates, that requires high availability.
--> Limitations:
	- They don't work with every data type. You must be able to define an appropriate merge function.
	-Some data types require complex merge functions that require the use of tombstones.
	- A tombstone is a marker that shows something was deleted.
	- Tombstones can result in data types that only get larger and never smaller
--> Distributed Data and the CAP Theorm:
	- Distributed Data is a solution for High Availability.
	- Distributed Data will ensure that the data is asynchronously replicated to all nodes.
	- Distributed Data is primarily intended to be an Availability Solution. It is Eventually Consistent.
	- Depending on the write consistency you can choose to push it towards a more Consistent approach, at the cost of Availability.

 -->  CRDTs: reduced the amount of contention in the system.
 
 --> So, CAP Theorm gave a challenge to choose between, Strong Consistency or High Availability.
 --> The choices b/w Consistency and availability isn't a technical but is a business decision.
 --> Its also rarely an either/or solution. It's usually about balance.
 --> The decision of when and where to sacrifice Consistency or Availability should be discussed with the
      domain experts and product owners.
 --> We need to factor in the impact of revenue if the system is unavailable v/s eventual consistency.      

























